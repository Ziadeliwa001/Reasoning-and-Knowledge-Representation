{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c7ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057d7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_implication(expression):\n",
    "    p = expression.split(\"->\")\n",
    "    return expression.replace(\"->\", \" v \").replace(p[0] or p[1],\"~\" + p[0] or p[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f689689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~(p v q)  v  (~p ∨ q)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"(p v q) -> (~p ∨ q)\"\n",
    "eliminate_implication(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8ea2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: ~(p v q)  v  (~p v q)\n",
      "Transformed sentence: ~p ∧ ~q v ( ~p v q )\n"
     ]
    }
   ],
   "source": [
    "def move_negation_inward(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    transformed_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        token = tokens[i]\n",
    "        if token == '~':\n",
    "            # Check if the next token is a left parenthesis indicating the start of a sub-expression\n",
    "            if i < len(tokens) - 1 and tokens[i + 1] == '(':\n",
    "                # Find the corresponding right parenthesis to the left parenthesis\n",
    "                left_parenthesis_count = 1\n",
    "                j = i + 2\n",
    "                while j < len(tokens):\n",
    "                    if tokens[j] == '(':\n",
    "                        left_parenthesis_count += 1\n",
    "                    elif tokens[j] == ')':\n",
    "                        left_parenthesis_count -= 1\n",
    "                    if left_parenthesis_count == 0:\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                # Move the negation inward by applying De Morgan's law\n",
    "                sub_expression = ' '.join(tokens[i + 2:j])\n",
    "                sub_tokens = word_tokenize(sub_expression)\n",
    "                transformed_sub_tokens = []\n",
    "                prev_token_was_negation = False\n",
    "                for token in sub_tokens:\n",
    "                    if token == '~':\n",
    "                        prev_token_was_negation = True\n",
    "                    elif token == '∧':\n",
    "                        if prev_token_was_negation:\n",
    "                            prev_token_was_negation = False\n",
    "                            continue  # Skip appending the previous '~'\n",
    "                        transformed_sub_tokens.append('v')\n",
    "                    elif token == 'v':\n",
    "                        if prev_token_was_negation:\n",
    "                            prev_token_was_negation = False\n",
    "                            continue  # Skip appending the previous '~'\n",
    "                        transformed_sub_tokens.append('∧')\n",
    "                    else:\n",
    "                        if prev_token_was_negation:\n",
    "                            transformed_sub_tokens.append(token)\n",
    "                            prev_token_was_negation = False\n",
    "                        else:\n",
    "                            transformed_sub_tokens.append('~' + token)\n",
    "                \n",
    "                transformed_tokens.extend(transformed_sub_tokens)\n",
    "                i = j + 1\n",
    "            else:\n",
    "                transformed_tokens.append(token)\n",
    "                i += 1\n",
    "        else:\n",
    "            transformed_tokens.append(token)\n",
    "            i += 1\n",
    "    transformed_sentence = ' '.join(transformed_tokens)\n",
    "    return transformed_sentence\n",
    "\n",
    "sentence = \"~(p v q)  v  (~p v q)\"\n",
    "transformed_sentence = move_negation_inward(sentence)\n",
    "print(\"Original sentence:\", sentence)\n",
    "print(\"Transformed sentence:\", transformed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2ca00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_not(expression):\n",
    "    return expression.replace(\"~~\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35217aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"~~~~p\"\n",
    "remove_double_not(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd9183b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(∀x P( x)) ∨ (∃a Q( a)) v (∀b Q( b))\n"
     ]
    }
   ],
   "source": [
    "def standardize_variable_Scope(Expressions):\n",
    "    exp = Expressions.split(\"', '\")\n",
    "    standardizedExpressions = []\n",
    "    for expression in exp:\n",
    "        new_expr = expression\n",
    "        variables = set()\n",
    "        replacement_map = {}\n",
    "        quantifier_found = False\n",
    "        quantifier_var = None\n",
    "        quantifier_replacement = None\n",
    "        def new_variable(old_var):\n",
    "            if old_var in replacement_map:\n",
    "                return replacement_map[old_var]\n",
    "            NEW_var = chr(ord('a') + len(variables))\n",
    "            while NEW_var in variables:\n",
    "                NEW_var = chr(ord(NEW_var) + 1)\n",
    "            variables.add(NEW_var)\n",
    "            replacement_map[old_var] = NEW_var\n",
    "            return NEW_var\n",
    "        i = 0\n",
    "        while i < len(new_expr):\n",
    "            if new_expr[i] in \"∀∃\":\n",
    "                quantifier = new_expr[i]\n",
    "                var = new_expr[i+1]\n",
    "                if var.islower():\n",
    "                    if not quantifier_found:\n",
    "                        quantifier_found = True\n",
    "                        quantifier_var = var\n",
    "                        uantifier_replacement = var\n",
    "                    else:\n",
    "                        NEW_var = new_variable(var)\n",
    "                        new_expr = new_expr[:i+1] + new_expr[i+1:].replace(var, NEW_var)\n",
    "                        i += len(NEW_var) - 1\n",
    "            i += 1\n",
    "        standardizedExpressions.append(new_expr)\n",
    "    return \"', '\".join(standardizedExpressions)\n",
    "test = \"(∀x P( x)) ∨ (∃x Q( x)) v (∀x Q( x))\"\n",
    "print(standardize_variable_Scope(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3887898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∀x ∃y ∃z ( P(x)) ∨ ( Q(y)) ∧ ( Q(z))\n"
     ]
    }
   ],
   "source": [
    "def prenex_form(expression):\n",
    "    quantifiers = {'∀', '∃'}\n",
    "    quantifier_part = \"\"\n",
    "    rest_part = \"\"\n",
    "    quantifier_buffer = \"\"\n",
    "    for char in expression:\n",
    "        if char in quantifiers:\n",
    "            quantifier_buffer += char\n",
    "        elif char == '(' and quantifier_buffer:\n",
    "            quantifier_part += quantifier_buffer + ' '\n",
    "            quantifier_buffer = \"\"\n",
    "        elif char.isalpha() and quantifier_buffer:\n",
    "            quantifier_part += quantifier_buffer + char + ' '\n",
    "            quantifier_buffer = \"\"\n",
    "        else:\n",
    "            rest_part += char\n",
    "\n",
    "    return quantifier_part + rest_part.strip()\n",
    "\n",
    "expression = \"(∀x P(x)) ∨ (∃y Q(y)) ∧ (∃z Q(z))\"\n",
    "print(prenex_form(expression))  # Output: ∀x ∃y P( x) ∨ Q( y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6177c6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∀x    P(x) ∨ Q(f(x)) v S(f(x))\n"
     ]
    }
   ],
   "source": [
    "def Skolemization(expression, universalVars=None, skolemFuncs=None, usedVars=None):\n",
    "    if universalVars is None:\n",
    "        universalVars = []\n",
    "    if skolemFuncs is None:\n",
    "        skolemFuncs = {}\n",
    "    if usedVars is None:\n",
    "        usedVars = set() \n",
    "\n",
    "    i = 0\n",
    "    new_expression = \"\"\n",
    "    default = None  \n",
    "    while i < len(expression):\n",
    "        if expression[i] in [\"∀\", \"∃\"]:\n",
    "            Quantf = expression[i]\n",
    "            var = expression[i + 1]\n",
    "            if Quantf == \"∀\":\n",
    "                universalVars.append(var)\n",
    "                if default is None:  \n",
    "                    default = var\n",
    "                # Include ∀ quantifiers and variables in the new formula\n",
    "                new_expression += f\"{Quantf}{var} \"\n",
    "            else:  # quantifier == \"∃\"\n",
    "                if universalVars:\n",
    "                    # Use the first unused universal variable for the Skolem function, if available\n",
    "                    for u_var in universalVars:\n",
    "                        if u_var not in usedVars:\n",
    "                            skolem_term = f\"f({u_var})\"\n",
    "                            usedVars.add(u_var)\n",
    "                            break\n",
    "                    else:\n",
    "\n",
    "                        skolem_term = f\"f({default})\"\n",
    "                else:\n",
    "                    skolem_term = \"c\" \n",
    "                skolemFuncs[var] = skolem_term\n",
    "            i += 2  # Skip past the quantifier and variable\n",
    "            continue\n",
    "        elif expression[i] in skolemFuncs:\n",
    "        \n",
    "            var = expression[i]\n",
    "            skolem_term = skolemFuncs[var]\n",
    "            new_expression += skolem_term\n",
    "            i += 1  # Adjust the index after replacement\n",
    "        else:\n",
    "            # Directly add other characters to the new formula\n",
    "            new_expression += expression[i]\n",
    "            i += 1\n",
    "\n",
    "    return new_expression\n",
    "str1 = \"∀x ∃y ∃z P(x) ∨ Q(y) v S(z)\"\n",
    "print (Skolemization(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac826ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x) ∨ Q(F(x))\n"
     ]
    }
   ],
   "source": [
    "# def eliminate_universal_quantifiers(expression):# like ∃x or ∀x\n",
    "#     quantifiers = {'∀', '∃'}\n",
    "#     quantifier_part = \"\"\n",
    "#     rest_part = \"\"\n",
    "#     quantifier_buffer = \"\"\n",
    "#     for char in expression:\n",
    "#         if char in quantifiers:\n",
    "#             quantifier_buffer += char\n",
    "#         elif char == '(' and quantifier_buffer:\n",
    "#             quantifier_part += quantifier_buffer + ' '\n",
    "#             quantifier_buffer = \"\"\n",
    "#         elif char.isalpha() and quantifier_buffer:\n",
    "#             quantifier_part += quantifier_buffer + char + ' '\n",
    "#             quantifier_buffer = \"\"\n",
    "#         else:\n",
    "#             rest_part += char\n",
    "\n",
    "#     return rest_part.strip()\n",
    "\n",
    "\n",
    "# expression = \"∀x(∃yP(y) ∨ ∀u∃v(R(x, u) ∨ Q(x, v))\"\n",
    "# print(eliminate_universal_quantifiers(expression))  # Output: ∀x(P(f(x)) ∨ ∀u(R(x, u) ∨ Q(x, g(x, u))\n",
    "def eliminate_universal_quantifiers(expression):\n",
    "    return re.sub(r'∀\\w+\\s', '', expression)\n",
    "\n",
    "expression = \"∀x P(x) ∨ Q(F(x))\"\n",
    "print(eliminate_universal_quantifiers(expression))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c4163a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TO_CNF(Expr):\n",
    "    print(\"Before CNF: \", Expr)\n",
    "   # Step 1\n",
    "    s1 = eliminate_implication(Expr)\n",
    "    # Step 2\n",
    "    s2 = move_negation_inward(s1)\n",
    "    # Step 3\n",
    "    s3 = remove_double_not(s2)\n",
    "    # Step 4\n",
    "    s4 = standardize_variable_Scope(s3)\n",
    "    # Step 5\n",
    "    s5 = prenex_form(s4)\n",
    "    # Step 6\n",
    "    s6 = Skolemization(s5)\n",
    "    # Step 7\n",
    "    s7 = eliminate_universal_quantifiers(s6)\n",
    "    return s7\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2979b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before CNF:  ∀x∃y∃z((l(x,y)∧l(y,z))∧(r(z)->p(z))∧(p(z)->r(z)))\n",
      "1    ~ ( ( l ( x , f(x) ) ∧l ( f(x) , f(x) ) ) ∧ ( r ( f(x) ) v p ( f(x) ) ) ∧ ( p ( f(x) ) v r ( f(x) ) ) )\n",
      "Before CNF:  ~~(p(a))\n",
      "2 ~ ( p ( a ) )\n",
      "Before CNF:  ∀x∀y∀z(f(x,y)->f(y,z))∧(f(x,z))\n",
      "3    ~ ( f ( x , a ) v f ( a , b ) ) ∧ ( f ( x , b ) )\n",
      "Before CNF:  ∀x(∃y(p(y,d,b,c))∨q(d,b))∧p(x,y)->r(x)\n",
      "4   ~ (  ( p ( f(x) , d , b , c ) ) ∨q ( d , b ) ) ∧p ( x , f(x) ) v r ( x )\n",
      "Before CNF:  ∀x∃y∃z((l(x,y)∧l(y,z))∧(r(z)->p(z))∧(p(z)->r(z)))\n",
      "5    ~ ( ( l ( x , f(x) ) ∧l ( f(x) , f(x) ) ) ∧ ( r ( f(x) ) v p ( f(x) ) ) ∧ ( p ( f(x) ) v r ( f(x) ) ) )\n",
      "Before CNF:  ∀x((~(p(a))∧(q(a))))\n",
      "6  ~ ( ( ~p ~( ~a ~) ∧ ( q ( a ) ) ) )\n",
      "Before CNF:  ∀x∀z∀u∀w((p(x,f(x),z))∨(p(u,w,w)))\n",
      "7     ~ ( ( p ( x , f ( x ) , a ) ) ∨ ( p ( b , c , c ) ) )\n",
      "Before CNF:  ∀x∀a∀b((p(x,a,b)) ∨ (p(b,b,b)))\n",
      "8    ~ ( ( p ( x , a , b ) ) ∨ ( p ( b , b , b ) ) )\n"
     ]
    }
   ],
   "source": [
    "STR2 = \"∀x∃y∃z((l(x,y)∧l(y,z))∧(r(z)->p(z))∧(p(z)->r(z)))\"\n",
    "STR3 = \"~~(p(a))\"\n",
    "STR4 = \"∀x∀y∀z(f(x,y)->f(y,z))∧(f(x,z))\"\n",
    "STR5 = \"∀x(∃y(p(y,d,b,c))∨q(d,b))∧p(x,y)->r(x)\"\n",
    "STR6 = \"∀x∃y∃z((l(x,y)∧l(y,z))∧(r(z)->p(z))∧(p(z)->r(z)))\"\n",
    "STR7 = \"∀x((~(p(a))∧(q(a))))\"\n",
    "STR8 = \"∀x∀z∀u∀w((p(x,f(x),z))∨(p(u,w,w)))\"\n",
    "STR9 = \"∀x∀a∀b((p(x,a,b)) ∨ (p(b,b,b)))\"\n",
    "print(\"1\", TO_CNF(STR2))\n",
    "print(\"2\", TO_CNF(STR3))\n",
    "print(\"3\", TO_CNF(STR4))\n",
    "print(\"4\", TO_CNF(STR5))\n",
    "print(\"5\", TO_CNF(STR6))\n",
    "print(\"6\", TO_CNF(STR7))\n",
    "print(\"7\", TO_CNF(STR8))\n",
    "print(\"8\", TO_CNF(STR9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eba7c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "def turn_conjunctions_into_clauses(cnf_expression):\n",
    "    if isinstance(cnf_expression, sympy.And):\n",
    "        clauses = set(cnf_expression.args)\n",
    "    else:\n",
    "        clauses = set([cnf_expression])\n",
    "    \n",
    "    # Replace logical OR symbol with comma\n",
    "    clauses_str = [str(clause).replace('∨', ',') if '∧' not in str(clause) else str(clause).replace('∧', '}    {') for clause in clauses]\n",
    "    \n",
    "    return set(clauses_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "32152fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'∀x P(x) ∨ Q(F(x)) }    { (Q(F(z))∨ Q(F(x))) '}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression = \"∀x P(x) ∨ Q(F(x)) ∧ (Q(F(z))∨ Q(F(x))) \"\n",
    "turn_conjunctions_into_clauses(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eff614bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_variables(clauses):\n",
    "    unique_var_names = [sympy.Symbol(f'var{i}') for i in range(len(clauses))]\n",
    "    substitutions = dict(zip(clauses, unique_var_names))\n",
    "    renamed_clauses = [clause.subs(substitutions) for clause in clauses]\n",
    "    return renamed_clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04301f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
